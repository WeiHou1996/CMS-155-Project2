{"cells":[{"cell_type":"markdown","metadata":{"id":"s1b6zO-CSaVG"},"source":["# Mini Project2\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"6P-a96GSSaVJ"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import requests"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Start downloading...\n","Complete\n","Start downloading...\n","Complete\n","Start downloading...\n","Complete\n","Start downloading...\n","Complete\n"]}],"source":["url_dict = {\n","     'data.csv': 'https://caltech-cs155.s3.us-east-2.amazonaws.com/sets/miniprojects/project2/data/data.csv',\n","     'movies.csv': 'https://caltech-cs155.s3.us-east-2.amazonaws.com/sets/miniprojects/project2/data/movies.csv',\n","     'train.csv': 'https://caltech-cs155.s3.us-east-2.amazonaws.com/sets/miniprojects/project2/data/train.csv',\n","     'test.csv': 'https://caltech-cs155.s3.us-east-2.amazonaws.com/sets/miniprojects/project2/data/test.csv'\n","}\n","\n","def download_file(file_path):\n","    url = url_dict[file_path]\n","    print('Start downloading...')\n","    with requests.get(url, stream=True) as r:\n","        r.raise_for_status()\n","        with open(file_path, 'wb') as f:\n","            for chunk in r.iter_content(chunk_size=1024 * 1024 * 1024):\n","                f.write(chunk)\n","    print('Complete')\n","\n","download_file('data.csv')\n","download_file('movies.csv')\n","download_file('train.csv')\n","download_file('test.csv')"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"HrO0jULdSaVK"},"outputs":[],"source":["def grad_U(Ui, Yij, Vj, reg, eta, mu):\n","    \"\"\"\n","    Takes as input Ui (the ith row of U), a training point Yij, the column\n","    vector Vj (jth column of V^T), reg (the regularization parameter lambda),\n","    and eta (the learning rate).\n","\n","    Returns the gradient of the regularized loss function with\n","    respect to Ui multiplied by eta.\n","    \"\"\"\n","    \n","    grad = reg*Ui - Vj * ((Yij-mu) - np.dot(Ui,Vj))\n","\n","    foo = eta*grad\n","\n","    return foo\n","        \n","\n","def grad_V(Vj, Yij, Ui, reg, eta, mu):\n","    \"\"\"\n","    Takes as input the column vector Vj (jth column of V^T), a training point Yij,\n","    Ui (the ith row of U), reg (the regularization parameter lambda),\n","    and eta (the learning rate).\n","\n","    Returns the gradient of the regularized loss function with\n","    respect to Vj multiplied by eta.\n","    \"\"\"\n","\n","    grad = reg*Vj - Ui * ((Yij-mu) - np.dot(Ui,Vj))\n","\n","    foo = eta*grad\n","\n","    return foo\n","\n","def get_err(U, V, Y, mu, reg=0.0):\n","    \"\"\"\n","    Takes as input a matrix Y of triples (i, j, Y_ij) where i is the index of a user,\n","    j is the index of a movie, and Y_ij is user i's rating of movie j and\n","    user/movie matrices U and V.\n","\n","    Returns the mean regularized squared-error of predictions made by\n","    estimating Y_{ij} as the dot product of the ith row of U and the jth column of V^T.\n","    \"\"\"\n","\n","    N = Y.shape[0]\n","    err = 0\n","    for i in range(N):\n","        Y_idx = Y[i]\n","        Ui  = U[Y_idx[0]-1,:]\n","        Vj  = V[Y_idx[1]-1,:]\n","        Yij = Y_idx[2]\n","\n","        err += ((Yij-mu) - np.dot(Ui,Vj))**2\n","\n","    err = err/(2*N)\n","\n","    return err\n","\n","\n","def train_model(M, N, K, eta, reg, Y, mu, eps=0.0001, max_epochs=300):\n","    \"\"\"\n","    Given a training data matrix Y containing rows (i, j, Y_ij)\n","    where Y_ij is user i's rating on movie j, learns an\n","    M x K matrix U and N x K matrix V such that rating Y_ij is approximated\n","    by (UV^T)_ij.\n","\n","    Uses a learning rate of <eta> and regularization of <reg>. Stops after\n","    <max_epochs> epochs, or once the magnitude of the decrease in regularized\n","    MSE between epochs is smaller than a fraction <eps> of the decrease in\n","    MSE after the first epoch.\n","\n","    Returns a tuple (U, V, err) consisting of U, V, and the unregularized MSE\n","    of the model.\n","    \"\"\"\n","\n","    U = np.random.uniform(-0.5,0.5,size=(M,K)) \n","    V = np.random.uniform(-0.5,0.5,size=(N,K))\n","\n","    err_0 = get_err(U, V, Y, mu) \n","\n","    N = Y.shape[0]\n","    \n","    for c in range(max_epochs):\n","        j = np.random.permutation(np.array(range(N)))\n","        for i in j:\n","            Y_idx  = Y[i]\n","            Ui  = U[Y_idx[0]-1,:]\n","            Vj  = V[Y_idx[1]-1,:]\n","            Yij = Y_idx[2]\n","\n","            Ui_new  = Ui - grad_U(Ui,Yij,Vj, reg, eta, mu)\n","            Vj_new  = Vj - grad_V(Vj,Yij,Ui, reg, eta, mu)\n","        \n","\n","            U[Y_idx[0]-1,:] = Ui_new\n","            V[Y_idx[1]-1,:] = Vj_new\n","\n","        err = get_err(U, V, Y, mu)\n","\n","        if c == 0:\n","            err_int = np.abs(err-err_0)\n","            err_1 = 0\n","        \n","        err_ratio = (err_1-err)/err_int\n","\n","        if (err_ratio < eps) and (err_ratio > 0):\n","            break\n","        \n","        err_1 = err\n","\n","    return U, V, err"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["data = np.array(pd.read_csv('data.csv'))\n","movies = np.array(pd.read_csv('movies.csv'))\n","train = np.array(pd.read_csv('train.csv'))\n","test = np.array(pd.read_csv('test.csv'))\n","\n","N = train.shape[0]\n","mu = 0\n","for i in range(N):\n","    Y_idx = train[i]\n","    Yij   = Y_idx[2]\n","    mu += Yij\n","mu_train = mu/N\n","mu_train = 0\n","\n","N = test.shape[0]\n","mu = 0\n","for i in range(N):\n","    Y_idx = test[i]\n","    Yij   = Y_idx[2]\n","    mu += Yij\n","mu_test = mu/N\n","mu_test = 0"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"SmexnMN5SaVL"},"outputs":[{"name":"stdout","output_type":"stream","text":["Factorizing with  943  users,  1682  movies.\n","Training model with M = 943, N = 1682, k = 20, eta = 0.03, reg = 0.0001\n","Training model with M = 943, N = 1682, k = 20, eta = 0.03, reg = 0.0002782559402207126\n","Training model with M = 943, N = 1682, k = 20, eta = 0.03, reg = 0.000774263682681127\n","Training model with M = 943, N = 1682, k = 20, eta = 0.03, reg = 0.002154434690031882\n","Training model with M = 943, N = 1682, k = 20, eta = 0.03, reg = 0.005994842503189409\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m reg \u001b[38;5;129;01min\u001b[39;00m regs:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining model with M = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, N = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, k = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, eta = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, reg = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m(M, N, K, eta, reg))\n\u001b[0;32m---> 14\u001b[0m     U,V, err \u001b[38;5;241m=\u001b[39m train_model(M, N, K, eta, reg, train, mu_train)\n\u001b[1;32m     15\u001b[0m     E_in\u001b[38;5;241m.\u001b[39mappend(err)\n\u001b[1;32m     16\u001b[0m     E_out\u001b[38;5;241m.\u001b[39mappend(get_err(U, V, test, mu_test))\n","Cell \u001b[0;32mIn[8], line 90\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(M, N, K, eta, reg, Y, mu, eps, max_epochs)\u001b[0m\n\u001b[1;32m     87\u001b[0m Vj  \u001b[38;5;241m=\u001b[39m V[Y_idx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:]\n\u001b[1;32m     88\u001b[0m Yij \u001b[38;5;241m=\u001b[39m Y_idx[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m---> 90\u001b[0m Ui_new  \u001b[38;5;241m=\u001b[39m Ui \u001b[38;5;241m-\u001b[39m grad_U(Ui,Yij,Vj, reg, eta, mu)\n\u001b[1;32m     91\u001b[0m Vj_new  \u001b[38;5;241m=\u001b[39m Vj \u001b[38;5;241m-\u001b[39m grad_V(Vj,Yij,Ui, reg, eta, mu)\n\u001b[1;32m     94\u001b[0m U[Y_idx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:] \u001b[38;5;241m=\u001b[39m Ui_new\n","Cell \u001b[0;32mIn[8], line 1\u001b[0m, in \u001b[0;36mgrad_U\u001b[0;34m(Ui, Yij, Vj, reg, eta, mu)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad_U\u001b[39m(Ui, Yij, Vj, reg, eta, mu):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    Takes as input Ui (the ith row of U), a training point Yij, the column\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    vector Vj (jth column of V^T), reg (the regularization parameter lambda),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    respect to Ui multiplied by eta.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     grad \u001b[38;5;241m=\u001b[39m reg\u001b[38;5;241m*\u001b[39mUi \u001b[38;5;241m-\u001b[39m Vj \u001b[38;5;241m*\u001b[39m ((Yij\u001b[38;5;241m-\u001b[39mmu) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(Ui,Vj))\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["M = max(max(train[:,0]), max(test[:,0])).astype(int) # users\n","N = max(max(train[:,1]), max(test[:,1])).astype(int) # movies\n","print(\"Factorizing with \", M, \" users, \", N, \" movies.\")\n","K = 20\n","\n","regs = np.logspace(-4,0,10)\n","eta = 0.03 # learning rate\n","E_in = []\n","E_out = []\n","\n","# Use to compute Ein and Eout\n","for reg in regs:\n","    print(\"Training model with M = %s, N = %s, k = %s, eta = %s, reg = %s\"%(M, N, K, eta, reg))\n","    U,V, err = train_model(M, N, K, eta, reg, train, mu_train)\n","    E_in.append(err)\n","    E_out.append(get_err(U, V, test, mu_test))\n","\n","plt.semilogx(regs, E_in, label='$E_{in}$')\n","plt.semilogx(regs, E_out, label='$E_{out}$')\n","plt.title('Error vs. K')\n","plt.xlabel(r'$\\lambda$')\n","plt.ylabel('Error')\n","plt.legend()\n","plt.savefig('set5_test.png')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["M = max(max(train[:,0]), max(test[:,0])).astype(int) # users\n","N = max(max(train[:,1]), max(test[:,1])).astype(int) # movies\n","print(\"Factorizing with \", M, \" users, \", N, \" movies.\")\n","K = 20\n","\n","regs = [10**-4, 10**-3, 10**-2, 10**-1, 1]\n","etas = [0.001, 0.005, 0.01, 0.03, 0.05, 0.1, 0.5, 1] # learning rate\n","E_ins = []\n","E_outs = []\n","\n","for eta in etas:\n","    E_ins_for_lambda = []\n","    E_outs_for_lambda = []\n","\n","    for reg in regs:\n","        print(\"Training model with M = %s, N = %s, k = %s, eta = %s, reg = %s\"%(M, N, K, eta, reg))\n","        U,V, e_in = train_model(M, N, K, eta, reg, train)\n","        E_ins_for_lambda.append(e_in)\n","        eout = get_err(U, V, test)\n","        E_outs_for_lambda.append(eout)\n","\n","    E_ins.append(E_ins_for_lambda)\n","    E_outs.append(E_outs_for_lambda)\n","\n","\n","# Plot values of E_in across k for each value of lambda\n","for i in range(len(etas)):\n","    plt.semilogx(regs, E_ins[i], label='$E_{in}, \\eta=$'+str(etas[i]))\n","plt.title('$E_{in}$ vs. $\\lambda$')\n","plt.xlabel('$\\lambda$')\n","plt.ylabel('Error')\n","plt.legend()\n","plt.savefig('2e_ein.png')\n","plt.clf()\n","\n","# Plot values of E_out across k for each value of lambda\n","for i in range(len(regs)):\n","    plt.semilogx(regs, E_outs[i], label='$E_{out}, \\eta=$'+str(etas[i]))\n","plt.title('$E_{out}$ vs. $\\lambda$')\n","plt.xlabel('$\\lambda$')\n","plt.ylabel('Error')\n","plt.legend()\n","plt.savefig('2e_eout.png')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["col = ['black','green','blue', 'orange','gray','red','purple','yellow']\n","\n","for i in range(len(etas)):\n","    plt.semilogx(regs, E_ins[i], color=col[i], label='$E_{in}, \\eta=$'+str(etas[i]))\n","    plt.semilogx(regs, E_outs[i], color=col[i], linestyle='--')\n","plt.title('$E$ vs. $\\lambda$')\n","plt.xlabel('$\\lambda$')\n","plt.ylabel('Error')\n","plt.legend()\n","plt.savefig('2e_error.png')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
